{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "! pip install -q polyline python-geohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/final-etarta/validation.csv\n",
      "/kaggle/input/final-etarta/test_additional.csv\n",
      "/kaggle/input/final-etarta/test.csv\n",
      "/kaggle/input/final-etarta/train.csv/train.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import geohash\n",
    "import polyline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm.autonotebook import tqdm\n",
    "from vowpalwabbit.sklearn_vw import VWRegressor\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature transofrmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_consecutive_duplicates(path):\n",
    "    return [point for point, _ in itertools.groupby(path)]\n",
    "\n",
    "def decode_polyline(path):\n",
    "    return drop_consecutive_duplicates(polyline.decode(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeohashBinarizer():\n",
    "    \"\"\"\n",
    "    Convert polylines to sparse feature matrix\n",
    "    Parameters\n",
    "    ----------\n",
    "    geohash_precision : int, default=6\n",
    "        6 => ~10000 features.\n",
    "        7 => ~100000 features.\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_features_ : int\n",
    "    mlb : MultiLabelBinarizer\n",
    "    \"\"\"\n",
    "    def __init__(self, geohash_precision=6):\n",
    "        self.geohash_precision = geohash_precision\n",
    "        self.mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "\n",
    "    def fit_transform(self, routes):\n",
    "        \"\"\"\n",
    "        routes : polylines or lists of points\n",
    "        \"\"\"\n",
    "        hashes = self.convert_to_hashes(routes)\n",
    "        features = self.mlb.fit_transform(hashes)\n",
    "        self.n_features_ = len(self.mlb.classes_)\n",
    "        return features\n",
    "\n",
    "    def transform(self, routes):\n",
    "        hashes = self.convert_to_hashes(routes)\n",
    "        features = self.mlb.transform(hashes)\n",
    "        return features\n",
    "    \n",
    "    def get_hashes(self, path):\n",
    "        return set(geohash.encode(*point, precision=self.geohash_precision) \n",
    "               for point in set(path))\n",
    "    \n",
    "    def convert_to_hashes(self, routes):\n",
    "        if isinstance(routes[0], str):\n",
    "            routes = [decode_polyline(path)\n",
    "                      for path in tqdm(routes, desc='Decoding polylines')]\n",
    "        hashes = [self.get_hashes(path)\n",
    "                  for path in tqdm(routes, desc='Creating geohashes')]\n",
    "        return hashes\n",
    "\n",
    "    \n",
    "class TurnAngleCounter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit_transform(self, series):\n",
    "        return pd.DataFrame(self.convert_to_counts(series), index=series.index)\n",
    "    \n",
    "    def turn_angle_cos(self, points):\n",
    "        (x1, y1), (x2, y2), (x3, y3) = points\n",
    "        seg1_x = x2-x1\n",
    "        seg1_y = y2-y1\n",
    "        seg2_x = x3-x2\n",
    "        seg2_y = y3-y2\n",
    "        seg1_conj_x = -seg1_y\n",
    "        seg1_conj_y = seg1_x\n",
    "        seg1_len = np.sqrt(seg1_x ** 2 + seg1_y ** 2)\n",
    "        seg2_len = np.sqrt(seg2_x ** 2 + seg2_y ** 2)\n",
    "        dot = seg1_conj_x * seg2_x + seg1_conj_y * seg2_y\n",
    "        return dot / (seg1_len * seg2_len)\n",
    "    \n",
    "    def get_path_angles(self, points):\n",
    "        angles = pd.Series([self.turn_angle_cos(points[i:i+3]) for i in range(len(points)-2)])\n",
    "        counts, _ = np.histogram(angles, bins=[-2, -0.95, -0.2, 0.2, 0.95, 2])\n",
    "        return pd.Series({\n",
    "            'left_60': counts[0],\n",
    "            'left_30': counts[1],\n",
    "            'straight': counts[2],\n",
    "            'right_30': counts[3],\n",
    "            'right_60': counts[4],\n",
    "        })\n",
    "    \n",
    "    def convert_to_counts(self, routes):\n",
    "        if isinstance(routes[0], str):\n",
    "            routes = [decode_polyline(path)\n",
    "                      for path in tqdm(routes, desc='Decoding polylines')]\n",
    "        counts = [self.get_path_angles(points)\n",
    "                  for points in tqdm(routes, desc='Counting angles')]\n",
    "        return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_polylines_to_pd(series):\n",
    "    return series.dropna().progress_apply(decode_polyline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/') / 'kaggle' / 'input' / 'preprocessed-citymobil' / 'preprocessed_citymobil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ETA</th>\n",
       "      <th>RTA</th>\n",
       "      <th>EDA</th>\n",
       "      <th>RDA</th>\n",
       "      <th>route</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>226.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gnvsIaq{jHChA??uC???OPG^F^NRzKBd@AN[r@???`@`@`...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>718.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>sqpsI}~zjHyAr]e@lMk@fLaBlb@i@rLKhBCdAUxEGlCg@f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>612.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>auosI}mmkH?LHd@KhC??o@w@[g@m@iAUk@??{G|OiB`Ek@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1560.0</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>{lhsIiffkHmKN_C?mIPwMJ??Si@gA{B??Wq@MRCJTp@hAd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1528.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>yxusI{xnjHgAfG??}IuHkAqA??pIoe@VsA??dAkG`BuH??...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ETA     RTA   EDA   RDA  \\\n",
       "Id                               \n",
       "0    226.0   188.0   1.0   1.0   \n",
       "1    718.0   725.0   5.0   6.0   \n",
       "2    612.0   764.0   5.0   5.0   \n",
       "3   1560.0  1412.0  13.0  14.0   \n",
       "4   1528.0   893.0   9.0  10.0   \n",
       "\n",
       "                                                route  \n",
       "Id                                                     \n",
       "0   gnvsIaq{jHChA??uC???OPG^F^NRzKBd@AN[r@???`@`@`...  \n",
       "1   sqpsI}~zjHyAr]e@lMk@fLaBlb@i@rLKhBCdAUxEGlCg@f...  \n",
       "2   auosI}mmkH?LHd@KhC??o@w@[g@m@iAUk@??{G|OiB`Ek@...  \n",
       "3   {lhsIiffkHmKN_C?mIPwMJ??Si@gA{B??Wq@MRCJTp@hAd...  \n",
       "4   yxusI{xnjHgAfG??}IuHkAqA??pIoe@VsA??dAkG`BuH??...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(data_path / 'train.csv', \n",
    "                 usecols=(\"Id\", \"ETA\", \"EDA\", \"RTA\", \"RDA\", \"route\"),\n",
    "                 index_col=\"Id\")\n",
    "df_val = pd.read_csv(data_path / 'validation.csv', \n",
    "                     usecols=(\"Id\", \"ETA\", \"EDA\", \"RTA\", \"RDA\", \"route\"),\n",
    "                     index_col=\"Id\")\n",
    "df_test = pd.read_csv(data_path / 'test_additional.csv', \n",
    "                      usecols=(\"Id\", \"ETA\", \"EDA\", \"route\"),\n",
    "                      index_col=\"Id\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "geohasher = GeohashBinarizer(geohash_precision=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwr = VWRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoFeatures:\n",
    "    def __init__(self, geohasher, vwr):\n",
    "        self.geohasher = geohasher\n",
    "        self.vwr = vwr\n",
    "    \n",
    "    def fit_transform(self, df, label=None):\n",
    "        decoded = self.get_decoded(df)\n",
    "        x = self.geohasher.transform(decoded)\n",
    "        mask = df.route.notna()\n",
    "        y = (df['ETA'][mask] / df['RTA'][mask]).to_numpy()\n",
    "        self.vwr.fit(x, y)\n",
    "        self.save(decoded, x)\n",
    "    \n",
    "    def transform(self, df, label=None):\n",
    "        decoded = self.get_decoded(df)\n",
    "        x = self.geohasher.transform(decoded)\n",
    "        self.save(decoded, x)\n",
    "        \n",
    "    def get_decoded(df):\n",
    "        decoded = decode_polylines_to_pd(df.route)\n",
    "        return decoded\n",
    "    \n",
    "    def save(decoded, x, label):\n",
    "        counts = TurnAngleCounter().fit_transform(decoded)\n",
    "        pred = self.vwr.predict(x)\n",
    "        pred = pd.Series(pred, index=decoded.index, name='geohash_based_prediction')\n",
    "        counts.add_prefix('turn_').join(pred).to_csv(f'geofeatures_{label}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_features = GeoFeatures(geohasher, vwr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_features.fit_transform(df_train, label='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_features.transform(df_val, label='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_features.transform(df_test, label='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transforms.pkl', 'wb') as f:\n",
    "    pickle.dump({'geohasher': geohasher}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwr.save('vwr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

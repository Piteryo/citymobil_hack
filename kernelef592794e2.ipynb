{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install -U git+https://github.com/optuna/optuna.git -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://getfile.dokpub.com/yandex/get/https://yadi.sk/d/YmyigRey-Nic9Q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mv YmyigRey-Nic9Q dataset.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip dataset.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install kaggle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp /kaggle/input/json-api/kaggle.json /root/.kaggle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!kaggle datasets download -d yurybelousov/preprocessed-citymobil","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/final-etarta/validation.csv\n/kaggle/input/final-etarta/test_additional.csv\n/kaggle/input/final-etarta/test.csv\n/kaggle/input/final-etarta/train.csv/train.csv\n/kaggle/input/json-api/kaggle.json\n/kaggle/input/training/hpo_Booster.joblib\n/kaggle/input/training/simple_LGBMRegressor.txt\n/kaggle/input/training/hpo_Booster.txt\n/kaggle/input/training/__notebook__.ipynb\n/kaggle/input/training/study.joblib\n/kaggle/input/training/custom.css\n/kaggle/input/training/__results__.html\n/kaggle/input/training/__output__.json\n/kaggle/input/training/simple_LGBMRegressor.joblib\n/kaggle/input/training/boostings/3.pkl\n/kaggle/input/training/boostings/14.pkl\n/kaggle/input/training/boostings/5.pkl\n/kaggle/input/training/boostings/21.pkl\n/kaggle/input/training/boostings/56.pkl\n/kaggle/input/training/boostings/59.pkl\n/kaggle/input/training/boostings/13.pkl\n/kaggle/input/training/boostings/62.pkl\n/kaggle/input/training/boostings/55.pkl\n/kaggle/input/training/boostings/37.pkl\n/kaggle/input/training/boostings/45.pkl\n/kaggle/input/training/boostings/11.pkl\n/kaggle/input/training/boostings/26.pkl\n/kaggle/input/training/boostings/31.pkl\n/kaggle/input/training/boostings/2.pkl\n/kaggle/input/training/boostings/1.pkl\n/kaggle/input/training/boostings/65.pkl\n/kaggle/input/training/boostings/42.pkl\n/kaggle/input/training/boostings/32.pkl\n/kaggle/input/training/boostings/7.pkl\n/kaggle/input/training/boostings/4.pkl\n/kaggle/input/training/boostings/24.pkl\n/kaggle/input/training/boostings/0.pkl\n/kaggle/input/training/boostings/36.pkl\n/kaggle/input/training/boostings/8.pkl\n/kaggle/input/training/boostings/60.pkl\n/kaggle/input/training/boostings/20.pkl\n/kaggle/input/training/boostings/28.pkl\n/kaggle/input/training/boostings/16.pkl\n/kaggle/input/training/boostings/23.pkl\n/kaggle/input/training/boostings/46.pkl\n/kaggle/input/training/boostings/6.pkl\n/kaggle/input/training/boostings/40.pkl\n/kaggle/input/training/boostings/33.pkl\n/kaggle/input/training/boostings/66.pkl\n/kaggle/input/training/boostings/51.pkl\n/kaggle/input/training/boostings/49.pkl\n/kaggle/input/training/boostings/22.pkl\n/kaggle/input/training/boostings/57.pkl\n/kaggle/input/training/boostings/18.pkl\n/kaggle/input/training/boostings/39.pkl\n/kaggle/input/training/boostings/27.pkl\n/kaggle/input/training/boostings/34.pkl\n/kaggle/input/training/boostings/29.pkl\n/kaggle/input/training/boostings/54.pkl\n/kaggle/input/training/boostings/47.pkl\n/kaggle/input/training/boostings/53.pkl\n/kaggle/input/training/boostings/52.pkl\n/kaggle/input/training/boostings/41.pkl\n/kaggle/input/training/boostings/9.pkl\n/kaggle/input/training/boostings/10.pkl\n/kaggle/input/training/boostings/44.pkl\n/kaggle/input/training/boostings/67.pkl\n/kaggle/input/training/boostings/35.pkl\n/kaggle/input/training/boostings/48.pkl\n/kaggle/input/training/boostings/63.pkl\n/kaggle/input/training/boostings/38.pkl\n/kaggle/input/training/boostings/50.pkl\n/kaggle/input/training/boostings/58.pkl\n/kaggle/input/training/boostings/17.pkl\n/kaggle/input/training/boostings/15.pkl\n/kaggle/input/training/boostings/12.pkl\n/kaggle/input/training/boostings/19.pkl\n/kaggle/input/training/boostings/25.pkl\n/kaggle/input/training/boostings/61.pkl\n/kaggle/input/training/boostings/64.pkl\n/kaggle/input/training/boostings/30.pkl\n/kaggle/input/training/boostings/43.pkl\n/kaggle/input/yury-data/preprocessed_citymobil/valid.csv\n/kaggle/input/yury-data/preprocessed_citymobil/test.csv\n/kaggle/input/yury-data/preprocessed_citymobil/train.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\ndef mean_absolute_percentage_error(y_true, y_pred):\n    mask = (y_true != 0)\n    return (np.fabs(y_true - y_pred) / y_true)[mask].mean() * 100\n\ndef calculate_metrics(y_true, y_pred):\n    print(f\"MAPE: {mean_absolute_percentage_error(y_true, y_pred)}\")\n    print(f\"mse: {mean_squared_error(y_true, y_pred)}\")\n    print(f\"r2: {r2_score(y_true, y_pred)}\")","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import gc\nimport json\nfrom datetime import timedelta\nfrom pathlib import Path\n\nimport category_encoders as ce\n\nfrom joblib import dump\nfrom tqdm.autonotebook import tqdm\ntqdm.pandas()\n\nfrom sklearn.cluster import MiniBatchKMeans\nimport catboost as cb\n\n","execution_count":3,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  if __name__ == '__main__':\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = Path('/') / 'kaggle' / 'input' / 'yury-data' / 'preprocessed_citymobil'","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(data_path / 'train.csv', index_col='Id')\nvalid = pd.read_csv(data_path / 'valid.csv', index_col='Id')\ntest = pd.read_csv(data_path / 'test.csv', index_col='Id')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"    main_id_locality     ETA     RTA          OrderedDate   latitude  \\\nId                                                                     \n0               1078   226.0   188.0  2020-02-12 19:12:06  55.826019   \n1               1078   718.0   725.0  2020-02-12 19:12:22  55.795502   \n2               1078   612.0   764.0  2020-02-12 19:12:44  55.791050   \n3               1078  1560.0  1412.0  2020-02-12 19:12:44  55.753899   \n4               1078  1528.0   893.0  2020-02-12 19:12:45  55.822361   \n\n    del_latitude  longitude  del_longitude   EDA   RDA  ...  \\\nId                                                      ...   \n0      55.825581  49.134529      49.126949   1.0   1.0  ...   \n1      55.820911  49.131470      49.115360   5.0   6.0  ...   \n2      55.819962  49.226070      49.176628   5.0   5.0  ...   \n3      55.824680  49.188519      49.093700  13.0  14.0  ...   \n4      55.786758  49.069092      49.143501   9.0  10.0  ...   \n\n   work_avg_speed_at_14 work_avg_speed_at_15 work_avg_speed_at_16  \\\nId                                                                  \n0              0.007848             0.007812             0.007144   \n1              0.007848             0.007812             0.007144   \n2              0.007848             0.007812             0.007144   \n3              0.007848             0.007812             0.007144   \n4              0.007848             0.007812             0.007144   \n\n    work_avg_speed_at_17  work_avg_speed_at_18  work_avg_speed_at_19  \\\nId                                                                     \n0                0.00629              0.006826              0.008095   \n1                0.00629              0.006826              0.008095   \n2                0.00629              0.006826              0.008095   \n3                0.00629              0.006826              0.008095   \n4                0.00629              0.006826              0.008095   \n\n    work_avg_speed_at_20  work_avg_speed_at_21  work_avg_speed_at_22  \\\nId                                                                     \n0               0.008686              0.009017               0.00931   \n1               0.008686              0.009017               0.00931   \n2               0.008686              0.009017               0.00931   \n3               0.008686              0.009017               0.00931   \n4               0.008686              0.009017               0.00931   \n\n    work_avg_speed_at_23  \nId                        \n0               0.009489  \n1               0.009489  \n2               0.009489  \n3               0.009489  \n4               0.009489  \n\n[5 rows x 157 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>main_id_locality</th>\n      <th>ETA</th>\n      <th>RTA</th>\n      <th>OrderedDate</th>\n      <th>latitude</th>\n      <th>del_latitude</th>\n      <th>longitude</th>\n      <th>del_longitude</th>\n      <th>EDA</th>\n      <th>RDA</th>\n      <th>...</th>\n      <th>work_avg_speed_at_14</th>\n      <th>work_avg_speed_at_15</th>\n      <th>work_avg_speed_at_16</th>\n      <th>work_avg_speed_at_17</th>\n      <th>work_avg_speed_at_18</th>\n      <th>work_avg_speed_at_19</th>\n      <th>work_avg_speed_at_20</th>\n      <th>work_avg_speed_at_21</th>\n      <th>work_avg_speed_at_22</th>\n      <th>work_avg_speed_at_23</th>\n    </tr>\n    <tr>\n      <th>Id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1078</td>\n      <td>226.0</td>\n      <td>188.0</td>\n      <td>2020-02-12 19:12:06</td>\n      <td>55.826019</td>\n      <td>55.825581</td>\n      <td>49.134529</td>\n      <td>49.126949</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.007848</td>\n      <td>0.007812</td>\n      <td>0.007144</td>\n      <td>0.00629</td>\n      <td>0.006826</td>\n      <td>0.008095</td>\n      <td>0.008686</td>\n      <td>0.009017</td>\n      <td>0.00931</td>\n      <td>0.009489</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1078</td>\n      <td>718.0</td>\n      <td>725.0</td>\n      <td>2020-02-12 19:12:22</td>\n      <td>55.795502</td>\n      <td>55.820911</td>\n      <td>49.131470</td>\n      <td>49.115360</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>0.007848</td>\n      <td>0.007812</td>\n      <td>0.007144</td>\n      <td>0.00629</td>\n      <td>0.006826</td>\n      <td>0.008095</td>\n      <td>0.008686</td>\n      <td>0.009017</td>\n      <td>0.00931</td>\n      <td>0.009489</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1078</td>\n      <td>612.0</td>\n      <td>764.0</td>\n      <td>2020-02-12 19:12:44</td>\n      <td>55.791050</td>\n      <td>55.819962</td>\n      <td>49.226070</td>\n      <td>49.176628</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>0.007848</td>\n      <td>0.007812</td>\n      <td>0.007144</td>\n      <td>0.00629</td>\n      <td>0.006826</td>\n      <td>0.008095</td>\n      <td>0.008686</td>\n      <td>0.009017</td>\n      <td>0.00931</td>\n      <td>0.009489</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1078</td>\n      <td>1560.0</td>\n      <td>1412.0</td>\n      <td>2020-02-12 19:12:44</td>\n      <td>55.753899</td>\n      <td>55.824680</td>\n      <td>49.188519</td>\n      <td>49.093700</td>\n      <td>13.0</td>\n      <td>14.0</td>\n      <td>...</td>\n      <td>0.007848</td>\n      <td>0.007812</td>\n      <td>0.007144</td>\n      <td>0.00629</td>\n      <td>0.006826</td>\n      <td>0.008095</td>\n      <td>0.008686</td>\n      <td>0.009017</td>\n      <td>0.00931</td>\n      <td>0.009489</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1078</td>\n      <td>1528.0</td>\n      <td>893.0</td>\n      <td>2020-02-12 19:12:45</td>\n      <td>55.822361</td>\n      <td>55.786758</td>\n      <td>49.069092</td>\n      <td>49.143501</td>\n      <td>9.0</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>0.007848</td>\n      <td>0.007812</td>\n      <td>0.007144</td>\n      <td>0.00629</td>\n      <td>0.006826</td>\n      <td>0.008095</td>\n      <td>0.008686</td>\n      <td>0.009017</td>\n      <td>0.00931</td>\n      <td>0.009489</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 157 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_city_speed(x):\n    if x['is_night']:\n        return x[f\"night_avg_speed_at_{x['hour']}\"]\n    \n    if x['is_rush_hour']:\n        return x[f\"rush_avg_speed_at_{x['hour']}\"]\n    \n    if x['is_weekend']:\n        return x[f\"weekend_avg_speed_at_{x['hour']}\"]\n    \n    return x[f\"work_avg_speed_at_{x['hour']}\"]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_estimated_speed(x):\n    return x['EDA'] / x['ETA']","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def speed_preprocessing(df):\n    df['current_city_speed'] = df.progress_apply(get_city_speed, axis=1)\n    df['estimated_speed'] = df.apply(get_estimated_speed, axis=1)\n    df['speed_difference'] = df['current_city_speed'] - df['estimated_speed']\n    df['speed_ratio'] = df['current_city_speed'] / df['estimated_speed']\n    df['detour_time'] = df['detour'] * df['estimated_speed']\n    return df","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = speed_preprocessing(train)\nvalid = speed_preprocessing(valid)\ntest = speed_preprocessing(test)","execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=803180.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af92889481e54e5a94a56c9cf71cc215"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=101354.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e4c939b2cc541aabe6e32c4790a47ee"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=89938.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1328e1fbb95542b58193bf66f4cd2930"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = test\ndf_val = valid","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['diff'] = np.abs(df['ETA'] - df['RTA'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = np.mean(df['diff'])\ns = np.std(df['diff'])\ndf = df[df['diff'] <= m + 3*s]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coords = np.vstack((df[['latitude', 'longitude']].values,\n                    df[['del_latitude', 'del_longitude']].values))","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_ind = np.random.permutation(len(coords))[:500000]\nkmeans = MiniBatchKMeans(n_clusters=100, batch_size=10000).fit(coords[sample_ind])","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[:, 'pickup_cluster'] = kmeans.predict(df[['latitude', 'longitude']])\ndf.loc[:, 'dropoff_cluster'] = kmeans.predict(df[['del_latitude', 'del_longitude']])\ndf_test.loc[:, 'pickup_cluster'] = kmeans.predict(df_test[['latitude', 'longitude']])\ndf_test.loc[:, 'dropoff_cluster'] = kmeans.predict(df_test[['del_latitude', 'del_longitude']])","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val.loc[:, 'pickup_cluster'] = kmeans.predict(df_val[['latitude', 'longitude']])\ndf_val.loc[:, 'dropoff_cluster'] = kmeans.predict(df_val[['del_latitude', 'del_longitude']])","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set(train.columns) - set(test.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shuffle train"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = df_test\nvalid = df_val","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.sample(frac=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_for_training = test.columns.difference(['OrderedDate'])","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train = train[columns_for_training], train['ETA'] - train['RTA']\nX_valid, y_valid = valid[columns_for_training], valid['ETA'] - valid['RTA']","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = list(X_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = ['main_id_locality', 'pickup_cluster', 'dropoff_cluster']","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_columns = ['day_of_week', 'hour'] #month\nencoder = ce.OrdinalEncoder(cols=ordinal_columns)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = encoder.fit_transform(X_train)\nX_valid = encoder.transform(X_valid)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = cb.CatBoostRegressor(iterations=500, rsm=0.8, depth=12, learning_rate=0.037, early_stopping_rounds=100)\nmodel.fit(X_train, y_train, categorical_columns + ordinal_columns,eval_set=(X_valid, y_valid), verbose=False, plot=True)","execution_count":26,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'X_val' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-207aa7458bf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.037\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_columns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mordinal_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'X_val' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_rows = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"X_train.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LGBMRegressor(\n            n_estimators=4000,\n            learning_rate=0.03,\n            num_leaves=30,\n            colsample_bytree=.8,\n            subsample=.9,\n            max_depth=7,\n            reg_alpha=.3,\n            reg_lambda=.1,\n            min_split_gain=.01,\n            min_child_weight=2,\n            verbose=2,  \n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(\n        X_train, y_train, \n        eval_set= [(X_train, y_train), (X_valid, y_valid)], \n        eval_metric='rmse', verbose=100, early_stopping_rounds=500, \n        feature_name=feature_names, categorical_feature=categorical_columns\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_valid_metrics(clf, prefix=''):\n    clf_name = f\"{prefix}_{clf.__class__.__name__}\"\n    print(f'Evaluating {clf_name}')\n    if hasattr(clf, 'booster_'):\n        clf.booster_.save_model(f'{clf_name}.txt')\n    elif hasattr(clf, 'save_model'):\n        clf.save_model(f'{clf_name}.txt')\n    dump(clf, f\"{clf_name}.joblib\")\n    \n    y_valid_pred = clf.predict(X_valid)\n    print(f\"Prediction diff: {y_valid_pred.mean()},\\tTrue diff: {(valid['ETA'] - valid['RTA']).mean()}\", end='\\t')\n    prediction_diff_bias = (valid['ETA'] - valid['RTA']).mean() - y_valid_pred.mean()\n    print(f'Difference: {prediction_diff_bias}')\n    \n    valid['pred_diff'] = y_valid_pred\n    valid['pred'] = valid['ETA'] - y_valid_pred\n    \n    prediction_diff_by_group = valid.groupby(by='main_id_locality').apply(lambda x: (x['ETA'] - x['RTA']).mean() - x['pred_diff'].mean()).to_frame(name = 'diff').reset_index()\n    print(prediction_diff_by_group)\n    \n    print(\"Diff metrics\")\n    calculate_metrics(y_valid, y_valid_pred)\n    \n    print(\"True RTA metrics\")\n    calculate_metrics(valid['RTA'], valid['pred'])\n    \n    print(\"True RTA metrics with bias substracting\")\n    calculate_metrics(valid['RTA'], valid['pred'] - prediction_diff_bias)\n    \n    print(\"True RTA metrics with bias substracting by group\")\n    calculate_metrics(valid['RTA'], valid['pred'] - valid.merge(prediction_diff_by_group)['diff'])\n    \n    return prediction_diff_bias, prediction_diff_by_group","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_diff_bias, prediction_diff_by_group = calculate_valid_metrics(clf, prefix='simple')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['RTA'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train['ETA'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_absolute_percentage_error(y_valid, clf.predict(X_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepate_test_submsission(clf, prediction_diff_bias, prediction_diff_by_group, prefix):\n    prefix = Path(prefix)\n    prefix.mkdir(exist_ok=True)\n    \n    X_test = test[columns_for_training]\n    X_test = encoder.transform(X_test)\n    \n    test_pred = clf.predict(X_test)\n    print(f\"Mean of diff on test is {test_pred.mean()}\")\n    \n    submission = test[['Id']].copy()\n    \n    submission['Prediction'] = test['ETA'] - test_pred\n    submission.to_csv(prefix / \"submission_pure.csv\", index=False)\n    \n    submission['Prediction'] = test['ETA'] - test_pred - prediction_diff_bias\n    submission.to_csv(prefix / \"submission_without_bias.csv\", index=False)\n    \n    submission['Prediction'] += valid['pred_diff'].mean() - test_pred.mean()\n    submission.to_csv(prefix / \"submission_without_bias_corrected.csv\", index=False)\n    \n    submission['main_id_locality'] = test['main_id_locality']\n    submission['Prediction'] = submission['Prediction'] - test.merge(prediction_diff_by_group)['diff']\n    submission.drop(columns='main_id_locality', inplace=True)\n    submission.to_csv(prefix / \"submission_without_bias_grouped.csv\", index=False)\n    \n    submission['Prediction'] += valid['pred_diff'].mean() - test_pred.mean()\n    submission.to_csv(prefix / \"submission_without_bias_grouped_corrected.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prepate_test_submsission(clf, prediction_diff_bias, prediction_diff_by_group, prefix='simple')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# HPO"},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna\nimport optuna.integration.lightgbm as lgb\noptuna.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train = lgb.Dataset(X_train, label=y_train, feature_name=feature_names, categorical_feature=categorical_columns, free_raw_data=False)\nd_valid = lgb.Dataset(X_valid, label=y_valid, feature_name=feature_names, categorical_feature=categorical_columns, free_raw_data=False)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boosting_static_params = {\n        \"objective\": \"regression\",\n        \"metric\": \"l2\",\n        \"verbosity\": 0,\n        # \"boosting_type\": \"gbdt\",\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_to_train = timedelta(hours=6).seconds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lgb.train(\n        params=boosting_static_params, \n        train_set=d_train, valid_sets=[d_valid], \n        early_stopping_rounds=100, num_boost_round=2000,\n        verbose_eval=0, \n        study=study, time_budget=time_to_train,\n        model_dir='/kaggle/working/boostings',\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dump(study, \"study.joblib\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_diff_bias, prediction_diff_by_group = calculate_valid_metrics(model, prefix='hpo')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prepate_test_submsission(model, prediction_diff_bias, prediction_diff_by_group, prefix='hpo')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Retrain on full dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Best parameters: ' + json.dumps(study.best_params, indent=4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as original_lightgbm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_retrained = original_lightgbm.train(\n    params={**boosting_static_params, **best_params, 'learning_rate': 0.03}, \n    train_set=d_train, valid_sets=[d_valid],\n    feature_name=feature_names, categorical_feature=categorical_columns,\n    init_model=model,\n    verbose_eval=400,\n    early_stopping_rounds=600, num_boost_round=4000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_diff_bias, prediction_diff_by_group = calculate_valid_metrics(model_retrained, prefix='hpo_retrained')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prepate_test_submsission(model_retrained, prediction_diff_bias, prediction_diff_by_group, prefix='hpo_retrained')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format ='retina'\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_importance(model, importance_type='split'):\n    \"\"\"\n    importance_type could be split or 'gain'\n    \"\"\"\n    feat_importance = pd.DataFrame()\n    feat_importance[\"feature\"] = X_train.columns\n    feat_importance[importance_type] = model.feature_importance(importance_type=importance_type)\n    feat_importance = feat_importance.sort_values(by=importance_type, ascending=False).head(20)\n    plt.figure(figsize=(20, 10))\n    ax = sns.barplot(y=\"feature\", x=importance_type, data=feat_importance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_importance(model_retrained, importance_type='split')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_importance(model_retrained, importance_type='gain')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}